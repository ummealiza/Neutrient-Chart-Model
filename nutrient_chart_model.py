# -*- coding: utf-8 -*-
"""Nutrient Chart Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dE38zaOIXGETmWNTJ4l1noWplUDa1mhk
"""

#Using KNN 
import pandas as pd
pd.set_option('display.max_rows', None)
from numpy import nan
from sklearn.preprocessing import LabelEncoder
from pandas import read_csv
dataset=pd.read_csv("/content/nutrients_csvfile.csv")
# a list with all missing value formats 
missing_value_formats = ["n.a" , "t" ,"t'" "a" , "?" , "--" , "n/a" ]
dataset = pd.read_csv("/content/nutrients_csvfile.csv", na_values = missing_value_formats)
#print(dataset.isnull())
dataset.fillna(dataset.mean(), inplace=True)
#print(dataset.head(25))
#dataset =dataset.replace(0,nan)

le=LabelEncoder()
print(dataset.shape)
dataset['Food type']=le.fit_transform(dataset['Food'])
dataset['Quantity']=le.fit_transform(dataset['Measure'])
#print(dataset.head(25))
#Delete columns after preprocessing
del dataset["Food"]
del dataset["Measure"]
#del dataset["Calories"]
#print(dataset.isnull())

print(dataset.head(25))
X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]
print(X_features_input)
y_label_output = dataset.iloc[:, 9].values #labels
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)
#x_train = 80% of our features data(input)
#x_test = 20% of our features data(input)
#y_train = 80% of our lable data(output)
#y_test = 20 % of pur lable data(output)
#imported the algorithms from library
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=5)
# to train the model you have to use the function of "fit()"
# while training we only pass the 80 percent of our data
classifier.fit(X_train,  y_train) # X_train = features #y_train= lable
# now we have to take prediction on testing data
y_pred = classifier.predict(X_test) #here we only pass the features
# from sklearn.metrics import classification_report, confusion_matrix
# print(confusion_matrix(y_test, y_pred))
#print(classification_report(y_test, y_pred))
print(y_pred)
#def evaluate_model(lin_reg,feature,real_label):
from sklearn.metrics import accuracy_score
print('Accuracy Score using KNN: ', accuracy_score(y_pred, y_test)) #y_pred is the output
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import f1_score
f1_metric = f1_score(y_test, y_pred, average = "macro")
#average="macro" it calculates the sperate precision and recall of
# each class and than take the average of precision and recall. after it calculate the f1 score
print("F1 Score macro:",f1_metric)
#
from sklearn.metrics import f1_score
f1_metric_micro = f1_score(y_test, y_pred, average = "micro")
print("F1 Score Micro:",f1_metric_micro)
# for accuracy
#from sklearn.metrics import accuracy_score
#print('Accuracy Score: ', accuracy_score(y_pred, y_test)) #y_pred is the output

#Using SVM
import pandas as pd
pd.set_option('display.max_rows', None)
from numpy import nan
from sklearn.preprocessing import LabelEncoder
from pandas import read_csv
dataset=pd.read_csv("/content/nutrients_csvfile.csv")
# a list with all missing value formats 
missing_value_formats = ["n.a" , "t" ,"t'" "a" , "?" , "--" , "n/a" ]
dataset = pd.read_csv("/content/nutrients_csvfile.csv", na_values = missing_value_formats)
#print(dataset.isnull())
dataset.fillna(dataset.mean(), inplace=True)
#print(dataset.head(25))
#dataset =dataset.replace(0,nan)

le=LabelEncoder()
print(dataset.shape)
dataset['Food type']=le.fit_transform(dataset['Food'])
dataset['Quantity']=le.fit_transform(dataset['Measure'])
#print(dataset.head(25))
#Delete columns after preprocessing
del dataset["Food"]
del dataset["Measure"]
#del dataset["Calories"]
#print(dataset.isnull())

print(dataset.head(25))
X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]
print(X_features_input)
y_label_output = dataset.iloc[:, 9].values #labels
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)
#x_train = 80% of our features data(input)
#x_test = 20% of our features data(input)
#y_train = 80% of our lable data(output)
#y_test = 20 % of pur lable data(output)
#imported the algorithms from library
from sklearn.svm import SVC
svclassifier = SVC(kernel='linear')
# to train the model you have to use the function of "fit()"
# while training we only pass the 80 percent of our data
svclassifier.fit(X_train,  y_train) # X_train = features #y_train= lable
# now we have to take prediction on testing data
y_pred = svclassifier.predict(X_test) #here we only pass the features
# from sklearn.metrics import classification_report, confusion_matrix
# print(confusion_matrix(y_test, y_pred))
#print(classification_report(y_test, y_pred))
print(y_pred)
#def evaluate_model(lin_reg,feature,real_label):
from sklearn.metrics import accuracy_score
print('Accuracy Score score using SVM:  ', accuracy_score(y_pred, y_test)) #y_pred is the output
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import f1_score
f1_metric = f1_score(y_test, y_pred, average = "macro")
#average="macro" it calculates the sperate precision and recall of
# each class and than take the average of precision and recall. after it calculate the f1 score
print("F1 Score macro:",f1_metric)
#
from sklearn.metrics import f1_score
f1_metric_micro = f1_score(y_test, y_pred, average = "micro")
print("F1 Score Micro:",f1_metric_micro)



#Using Decision Tree
import pandas as pd
pd.set_option('display.max_rows', None)
from numpy import nan
from sklearn.preprocessing import LabelEncoder
from pandas import read_csv
dataset=pd.read_csv("/content/nutrients_csvfile.csv")
# a list with all missing value formats 
missing_value_formats = ["n.a" , "t" ,"t'" "a" , "?" , "--" , "n/a" ]
dataset = pd.read_csv("/content/nutrients_csvfile.csv", na_values = missing_value_formats)
#print(dataset.isnull())
dataset.fillna(dataset.mean(), inplace=True)
#print(dataset.head(25))
#dataset =dataset.replace(0,nan)

le=LabelEncoder()
print(dataset.shape)
dataset['Food type']=le.fit_transform(dataset['Food'])
dataset['Quantity']=le.fit_transform(dataset['Measure'])
#print(dataset.head(25))
#Delete columns after preprocessing
del dataset["Food"]
del dataset["Measure"]
#del dataset["Calories"]
#print(dataset.isnull())

print(dataset.head(25))
X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]
print(X_features_input)
y_label_output = dataset.iloc[:, 9].values #labels
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)
#x_train = 80% of our features data(input)
#x_test = 20% of our features data(input)
#y_train = 80% of our lable data(output)
#y_test = 20 % of pur lable data(output)
#imported the algorithms from library
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier()
# to train the model you have to use the function of "fit()"
# while training we only pass the 80 percent of our data
classifier.fit(X_train,  y_train) # X_train = features #y_train= lable
# now we have to take prediction on testing data
y_pred = classifier.predict(X_test) #here we only pass the features
# from sklearn.metrics import classification_report, confusion_matrix
# print(confusion_matrix(y_test, y_pred))
#print(classification_report(y_test, y_pred))
print(y_pred)
#def evaluate_model(lin_reg,feature,real_label):
from sklearn.metrics import accuracy_score
print('Accuracy Score using Decision Tree: ', accuracy_score(y_pred, y_test)) #y_pred is the output
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import f1_score
f1_metric = f1_score(y_test, y_pred, average = "macro")
#average="macro" it calculates the sperate precision and recall of
# each class and than take the average of precision and recall. after it calculate the f1 score
print("F1 Score macro:",f1_metric)
#
from sklearn.metrics import f1_score
f1_metric_micro = f1_score(y_test, y_pred, average = "micro")
print("F1 Score Micro:",f1_metric_micro)



#Using Naive Bayes
import pandas as pd
pd.set_option('display.max_rows', None)
from numpy import nan
from sklearn.preprocessing import LabelEncoder
from pandas import read_csv
dataset=pd.read_csv("/content/nutrients_csvfile.csv")
# a list with all missing value formats 
missing_value_formats = ["n.a" , "t" ,"t'" "a" , "?" , "--" , "n/a" ]
dataset = pd.read_csv("/content/nutrients_csvfile.csv", na_values = missing_value_formats)
#print(dataset.isnull())
dataset.fillna(dataset.mean(), inplace=True)
#print(dataset.head(25))
#dataset =dataset.replace(0,nan)

le=LabelEncoder()
print(dataset.shape)
dataset['Food type']=le.fit_transform(dataset['Food'])
dataset['Quantity']=le.fit_transform(dataset['Measure'])
#print(dataset.head(25))
#Delete columns after preprocessing
del dataset["Food"]
del dataset["Measure"]
#del dataset["Calories"]
#print(dataset.isnull())

print(dataset.head(25))
X_features_input = dataset.iloc[:, :-1].values #features[rows, columms]
print(X_features_input)
y_label_output = dataset.iloc[:, 9].values #labels
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_features_input, y_label_output, test_size=0.20, random_state=5)
#x_train = 80% of our features data(input)
#x_test = 20% of our features data(input)
#y_train = 80% of our lable data(output)
#y_test = 20 % of pur lable data(output)
#imported the algorithms from library
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
# to train the model you have to use the function of "fit()"
# while training we only pass the 80 percent of our data
classifier.fit(X_train,  y_train) # X_train = features #y_train= lable
# now we have to take prediction on testing data
y_pred = classifier.predict(X_test) #here we only pass the features
# from sklearn.metrics import classification_report, confusion_matrix
# print(confusion_matrix(y_test, y_pred))
#print(classification_report(y_test, y_pred))
print(y_pred)
#def evaluate_model(lin_reg,feature,real_label):
from sklearn.metrics import accuracy_score
print('Accuracy Score using Naive Bayes : ', accuracy_score(y_pred, y_test)) #y_pred is the output
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import f1_score
f1_metric = f1_score(y_test, y_pred, average = "macro")
#average="macro" it calculates the sperate precision and recall of
# each class and than take the average of precision and recall. after it calculate the f1 score
print("F1 Score macro:",f1_metric)
#
from sklearn.metrics import f1_score
f1_metric_micro = f1_score(y_test, y_pred, average = "micro")
print("F1 Score Micro:",f1_metric_micro)

